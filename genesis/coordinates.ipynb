{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96734e09-c476-4f6a-9884-d5d5c28eaef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s-pose.pt to 'yolov8s-pose.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22.4M/22.4M [00:09<00:00, 2.53MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing video: D:\\FINAL PROJECT IG\\project_maal\\video\\jcr.mp4\n",
      "  Processed 100 frames...\n",
      "  Processed 200 frames...\n",
      "  Processed 300 frames...\n",
      "Finished processing D:\\FINAL PROJECT IG\\project_maal\\video\\jcr.mp4. Total frames saved: 308\n",
      "Pose coordinates saved to hoinu1.json\n",
      "\n",
      "Reference JSON file generation complete. Please use 'hoinu1.json' with your main cheating detection script.\n",
      "Remember to also update the 'left_cheating_landmarks.json' if needed, using a separate video.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import math\n",
    "import json\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "# Path to your input video file\n",
    "# IMPORTANT: This is now set to the video path you provided.\n",
    "video_path_to_process = r'D:\\FINAL PROJECT IG\\project_maal\\video\\jcr.mp4'\n",
    "\n",
    "# Output JSON file path\n",
    "# IMPORTANT: This is now set to the JSON file name you provided.\n",
    "output_json_path = 'hoinu1.json'\n",
    "\n",
    "# --- YOLOv8 Pose Model ---\n",
    "try:\n",
    "    model = YOLO(\"yolov8s-pose.pt\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading YOLOv8s-pose.pt model: {e}\")\n",
    "    print(\"Please ensure the model file is available and accessible in the same directory.\")\n",
    "    exit()\n",
    "\n",
    "# --- Normalization Function (identical to the one in your main detection code) ---\n",
    "def normalize_landmarks(landmarks):\n",
    "    \"\"\"\n",
    "    Normalizes landmark coordinates based on shoulder positions to make pose comparison\n",
    "    robust to scale and translation.\n",
    "    Landmarks expected as a list of dictionaries with 'x' and 'y' keys.\n",
    "    Assumes landmarks[5] is Left Shoulder and landmarks[6] is Right Shoulder (COCO 17-point).\n",
    "\n",
    "    Returns normalized list or None if normalization fails.\n",
    "    \"\"\"\n",
    "    # Minimum landmarks for normalization (need at least shoulders)\n",
    "    # COCO 17-keypoint set: Left Shoulder (5), Right Shoulder (6)\n",
    "    if len(landmarks) < 7: # Need at least 7 points to ensure shoulders are likely present\n",
    "        print(\"Warning: Not enough landmarks (less than 7) for normalization. Skipping normalization.\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        # Ensure the crucial shoulder landmarks exist and have 'x', 'y' keys.\n",
    "        # Check if indices 5 and 6 are within the bounds of the landmarks list.\n",
    "        if 5 not in range(len(landmarks)) or 6 not in range(len(landmarks)):\n",
    "             print(\"Warning: Shoulder landmarks (index 5 or 6) are missing in the detected set. Cannot normalize.\")\n",
    "             return None\n",
    "\n",
    "        left_shoulder = landmarks[5]   # Left Shoulder (COCO 17-point)\n",
    "        right_shoulder = landmarks[6]  # Right Shoulder (COCO 17-point)\n",
    "\n",
    "        # Also, ensure 'x' and 'y' keys are present in shoulder landmark dictionaries.\n",
    "        if not all(k in left_shoulder for k in ['x', 'y']) or \\\n",
    "           not all(k in right_shoulder for k in ['x', 'y']):\n",
    "            print(\"Warning: Shoulder landmark data incomplete (missing 'x' or 'y' keys). Cannot normalize.\")\n",
    "            return None\n",
    "\n",
    "        center_x = (left_shoulder[\"x\"] + right_shoulder[\"x\"]) / 2\n",
    "        center_y = (left_shoulder[\"y\"] + right_shoulder[\"y\"]) / 2\n",
    "\n",
    "        # Calculate scale based on distance between shoulders\n",
    "        scale = math.sqrt((left_shoulder[\"x\"] - right_shoulder[\"x\"]) ** 2 +\n",
    "                          (left_shoulder[\"y\"] - right_shoulder[\"y\"]) ** 2)\n",
    "        if scale == 0:\n",
    "            scale = 1e-6  # avoid division by zero\n",
    "\n",
    "        normalized = []\n",
    "        for lm in landmarks:\n",
    "            # Ensure each landmark in the loop also has 'x' and 'y' before normalizing\n",
    "            if 'x' in lm and 'y' in lm:\n",
    "                norm_x = (lm[\"x\"] - center_x) / scale\n",
    "                norm_y = (lm[\"y\"] - center_y) / scale\n",
    "                normalized.append({\"x\": norm_x, \"y\": norm_y})\n",
    "            else:\n",
    "                # If any landmark is missing 'x' or 'y' within the full list, consider normalization failed\n",
    "                print(f\"Warning: Skipping a landmark during normalization due to missing 'x' or 'y' data: {lm}\")\n",
    "                return None # Indicate normalization failure if data is incomplete\n",
    "        return normalized\n",
    "\n",
    "    except Exception as e: # Catch any other unexpected errors during normalization\n",
    "        print(f\"An unexpected error occurred during normalization: {e}\")\n",
    "        return None # Indicate failure to normalize\n",
    "\n",
    "# --- Function to process video and save landmarks ---\n",
    "def process_video_for_landmarks(video_path, output_json_path, model):\n",
    "    \"\"\"\n",
    "    Processes a video, extracts YOLOv8 pose landmarks, and saves them to a JSON file.\n",
    "    Only saves landmarks for the person with the most detected keypoints in each frame.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"Error: Video file not found at {video_path}\")\n",
    "        return\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error opening video file: {video_path}\")\n",
    "        return\n",
    "\n",
    "    all_frames_data = []\n",
    "    frame_count = 0\n",
    "    \n",
    "    print(f\"\\nProcessing video: {video_path}\")\n",
    "\n",
    "    while True:\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "        \n",
    "        # Perform pose estimation\n",
    "        results = model(frame, verbose=False)[0]\n",
    "\n",
    "        frame_data = {\n",
    "            \"frame\": frame_count,\n",
    "            \"landmarks\": []\n",
    "        }\n",
    "\n",
    "        if results.keypoints is not None and len(results.keypoints) > 0:\n",
    "            # Find the person with the most detected keypoints\n",
    "            best_person_keypoints_data = None\n",
    "            max_keypoints = 0\n",
    "\n",
    "            for person_kp_obj in results.keypoints:\n",
    "                current_person_keypoints_data = person_kp_obj.data.cpu().numpy()\n",
    "                if current_person_keypoints_data.ndim == 3 and current_person_keypoints_data.shape[0] == 1:\n",
    "                    current_person_keypoints_data = current_person_keypoints_data[0]\n",
    "\n",
    "                if len(current_person_keypoints_data) > max_keypoints:\n",
    "                    max_keypoints = len(current_person_keypoints_data)\n",
    "                    best_person_keypoints_data = current_person_keypoints_data\n",
    "            \n",
    "            if best_person_keypoints_data is not None:\n",
    "                height, width = frame.shape[:2]\n",
    "                current_frame_landmarks = []\n",
    "                # Convert YOLOv8 keypoints to your dictionary format (normalized x,y)\n",
    "                for id, kp in enumerate(best_person_keypoints_data):\n",
    "                    x_norm = kp[0] / width\n",
    "                    y_norm = kp[1] / height\n",
    "                    # Note: YOLOv8 keypoints have confidence at kp[2], which we can store as 'visibility'\n",
    "                    current_frame_landmarks.append({\n",
    "                        \"id\": id,\n",
    "                        \"x\": x_norm,\n",
    "                        \"y\": y_norm,\n",
    "                        \"visibility\": kp[2] # Store confidence as visibility\n",
    "                    })\n",
    "                \n",
    "                # Normalize these landmarks before saving\n",
    "                normalized_landmarks_for_frame = normalize_landmarks(current_frame_landmarks)\n",
    "                if normalized_landmarks_for_frame: # Only save if normalization was successful\n",
    "                    frame_data[\"landmarks\"] = normalized_landmarks_for_frame\n",
    "                else:\n",
    "                    print(f\"Warning: Normalization failed for frame {frame_count} in {video_path}. Skipping landmarks for this frame.\")\n",
    "        \n",
    "        all_frames_data.append(frame_data)\n",
    "        \n",
    "        # Optional: Display progress\n",
    "        if frame_count % 100 == 0:\n",
    "            print(f\"  Processed {frame_count} frames...\")\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # Write all the coordinates to a JSON file\n",
    "    with open(output_json_path, 'w') as f:\n",
    "        json.dump(all_frames_data, f, indent=4)\n",
    "    \n",
    "    print(f\"Finished processing {video_path}. Total frames saved: {len(all_frames_data)}\")\n",
    "    print(f\"Pose coordinates saved to {output_json_path}\")\n",
    "\n",
    "\n",
    "# --- Process the single video ---\n",
    "process_video_for_landmarks(video_path_to_process, output_json_path, model)\n",
    "\n",
    "print(\"\\nReference JSON file generation complete. Please use 'hoinu1.json' with your main cheating detection script.\")\n",
    "print(\"Remember to also update the 'left_cheating_landmarks.json' if needed, using a separate video.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e7f1c26-7131-4a66-8dec-03a18037b72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing video: D:\\FINAL PROJECT IG\\project_maal\\video\\jcl.mp4\n",
      "  Processed 100 frames...\n",
      "  Processed 200 frames...\n",
      "  Processed 300 frames...\n",
      "Finished processing D:\\FINAL PROJECT IG\\project_maal\\video\\jcl.mp4. Total frames saved: 369\n",
      "Pose coordinates saved to hoinu2.json\n",
      "\n",
      "Reference JSON file generation complete. Please use 'hoinu2.json' with your main cheating detection script.\n",
      "Remember to update the path in your main script to load 'hoinu2.json' for left turn landmarks.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import math\n",
    "import json\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "# Path to your input video file\n",
    "# IMPORTANT: This is now set to the video path you provided.\n",
    "video_path_to_process = r'D:\\FINAL PROJECT IG\\project_maal\\video\\jcl.mp4'\n",
    "\n",
    "# Output JSON file path\n",
    "# IMPORTANT: This is now set to the JSON file name you provided.\n",
    "output_json_path = 'hoinu2.json'\n",
    "\n",
    "# --- YOLOv8 Pose Model ---\n",
    "try:\n",
    "    model = YOLO(\"yolov8s-pose.pt\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading YOLOv8s-pose.pt model: {e}\")\n",
    "    print(\"Please ensure the model file is available and accessible in the same directory.\")\n",
    "    exit()\n",
    "\n",
    "# --- Normalization Function (identical to the one in your main detection code) ---\n",
    "def normalize_landmarks(landmarks):\n",
    "    \"\"\"\n",
    "    Normalizes landmark coordinates based on shoulder positions to make pose comparison\n",
    "    robust to scale and translation.\n",
    "    Landmarks expected as a list of dictionaries with 'x' and 'y' keys.\n",
    "    Assumes landmarks[5] is Left Shoulder and landmarks[6] is Right Shoulder (COCO 17-point).\n",
    "\n",
    "    Returns normalized list or None if normalization fails.\n",
    "    \"\"\"\n",
    "    # Minimum landmarks for normalization (need at least shoulders)\n",
    "    # COCO 17-keypoint set: Left Shoulder (5), Right Shoulder (6)\n",
    "    if len(landmarks) < 7: # Need at least 7 points to ensure shoulders are likely present\n",
    "        print(\"Warning: Not enough landmarks (less than 7) for normalization. Skipping normalization.\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        # Ensure the crucial shoulder landmarks exist and have 'x', 'y' keys.\n",
    "        # Check if indices 5 and 6 are within the bounds of the landmarks list.\n",
    "        if 5 not in range(len(landmarks)) or 6 not in range(len(landmarks)):\n",
    "             print(\"Warning: Shoulder landmarks (index 5 or 6) are missing in the detected set. Cannot normalize.\")\n",
    "             return None\n",
    "\n",
    "        left_shoulder = landmarks[5]   # Left Shoulder (COCO 17-point)\n",
    "        right_shoulder = landmarks[6]  # Right Shoulder (COCO 17-point)\n",
    "\n",
    "        # Also, ensure 'x' and 'y' keys are present in shoulder landmark dictionaries.\n",
    "        if not all(k in left_shoulder for k in ['x', 'y']) or \\\n",
    "           not all(k in right_shoulder for k in ['x', 'y']):\n",
    "            print(\"Warning: Shoulder landmark data incomplete (missing 'x' or 'y' keys). Cannot normalize.\")\n",
    "            return None\n",
    "\n",
    "        center_x = (left_shoulder[\"x\"] + right_shoulder[\"x\"]) / 2\n",
    "        center_y = (left_shoulder[\"y\"] + right_shoulder[\"y\"]) / 2\n",
    "\n",
    "        # Calculate scale based on distance between shoulders\n",
    "        scale = math.sqrt((left_shoulder[\"x\"] - right_shoulder[\"x\"]) ** 2 +\n",
    "                          (left_shoulder[\"y\"] - right_shoulder[\"y\"]) ** 2)\n",
    "        if scale == 0:\n",
    "            scale = 1e-6  # avoid division by zero\n",
    "\n",
    "        normalized = []\n",
    "        for lm in landmarks:\n",
    "            # Ensure each landmark in the loop also has 'x' and 'y' before normalizing\n",
    "            if 'x' in lm and 'y' in lm:\n",
    "                norm_x = (lm[\"x\"] - center_x) / scale\n",
    "                norm_y = (lm[\"y\"] - center_y) / scale\n",
    "                normalized.append({\"x\": norm_x, \"y\": norm_y})\n",
    "            else:\n",
    "                # If any landmark is missing 'x' or 'y' within the full list, consider normalization failed\n",
    "                print(f\"Warning: Skipping a landmark during normalization due to missing 'x' or 'y' data: {lm}\")\n",
    "                return None # Indicate normalization failure if data is incomplete\n",
    "        return normalized\n",
    "\n",
    "    except Exception as e: # Catch any other unexpected errors during normalization\n",
    "        print(f\"An unexpected error occurred during normalization: {e}\")\n",
    "        return None # Indicate failure to normalize\n",
    "\n",
    "# --- Function to process video and save landmarks ---\n",
    "def process_video_for_landmarks(video_path, output_json_path, model):\n",
    "    \"\"\"\n",
    "    Processes a video, extracts YOLOv8 pose landmarks, and saves them to a JSON file.\n",
    "    Only saves landmarks for the person with the most detected keypoints in each frame.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"Error: Video file not found at {video_path}\")\n",
    "        return\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error opening video file: {video_path}\")\n",
    "        return\n",
    "\n",
    "    all_frames_data = []\n",
    "    frame_count = 0\n",
    "    \n",
    "    print(f\"\\nProcessing video: {video_path}\")\n",
    "\n",
    "    while True:\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "        \n",
    "        # Perform pose estimation\n",
    "        results = model(frame, verbose=False)[0]\n",
    "\n",
    "        frame_data = {\n",
    "            \"frame\": frame_count,\n",
    "            \"landmarks\": []\n",
    "        }\n",
    "\n",
    "        if results.keypoints is not None and len(results.keypoints) > 0:\n",
    "            # Find the person with the most detected keypoints\n",
    "            best_person_keypoints_data = None\n",
    "            max_keypoints = 0\n",
    "\n",
    "            for person_kp_obj in results.keypoints:\n",
    "                current_person_keypoints_data = person_kp_obj.data.cpu().numpy()\n",
    "                if current_person_keypoints_data.ndim == 3 and current_person_keypoints_data.shape[0] == 1:\n",
    "                    current_person_keypoints_data = current_person_keypoints_data[0]\n",
    "\n",
    "                if len(current_person_keypoints_data) > max_keypoints:\n",
    "                    max_keypoints = len(current_person_keypoints_data)\n",
    "                    best_person_keypoints_data = current_person_keypoints_data\n",
    "            \n",
    "            if best_person_keypoints_data is not None:\n",
    "                height, width = frame.shape[:2]\n",
    "                current_frame_landmarks = []\n",
    "                # Convert YOLOv8 keypoints to your dictionary format (normalized x,y)\n",
    "                for id, kp in enumerate(best_person_keypoints_data):\n",
    "                    x_norm = kp[0] / width\n",
    "                    y_norm = kp[1] / height\n",
    "                    # Note: YOLOv8 keypoints have confidence at kp[2], which we can store as 'visibility'\n",
    "                    current_frame_landmarks.append({\n",
    "                        \"id\": id,\n",
    "                        \"x\": x_norm,\n",
    "                        \"y\": y_norm,\n",
    "                        \"visibility\": kp[2] # Store confidence as visibility\n",
    "                    })\n",
    "                \n",
    "                # Normalize these landmarks before saving\n",
    "                normalized_landmarks_for_frame = normalize_landmarks(current_frame_landmarks)\n",
    "                if normalized_landmarks_for_frame: # Only save if normalization was successful\n",
    "                    frame_data[\"landmarks\"] = normalized_landmarks_for_frame\n",
    "                else:\n",
    "                    print(f\"Warning: Normalization failed for frame {frame_count} in {video_path}. Skipping landmarks for this frame.\")\n",
    "        \n",
    "        all_frames_data.append(frame_data)\n",
    "        \n",
    "        # Optional: Display progress\n",
    "        if frame_count % 100 == 0:\n",
    "            print(f\"  Processed {frame_count} frames...\")\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # Write all the coordinates to a JSON file\n",
    "    with open(output_json_path, 'w') as f:\n",
    "        json.dump(all_frames_data, f, indent=4)\n",
    "    \n",
    "    print(f\"Finished processing {video_path}. Total frames saved: {len(all_frames_data)}\")\n",
    "    print(f\"Pose coordinates saved to {output_json_path}\")\n",
    "\n",
    "\n",
    "# --- Process the single video ---\n",
    "process_video_for_landmarks(video_path_to_process, output_json_path, model)\n",
    "\n",
    "print(\"\\nReference JSON file generation complete. Please use 'hoinu2.json' with your main cheating detection script.\")\n",
    "print(\"Remember to update the path in your main script to load 'hoinu2.json' for left turn landmarks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f13136-c847-4812-bc7a-33ac1d3114d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Finger Tracking)",
   "language": "python",
   "name": "finger_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
